# G1机器人控制系统 - 部署指南

**日期**: 2025年11月26日  
**系统**: G1机器人 + Jetson Thor VLM推理服务器

---

## 📋 目录

1. [系统架构概览](#系统架构概览)
2. [部署前准备](#部署前准备)
3. [G1机器人端部署](#g1机器人端部署)
4. [Thor服务器端部署](#thor服务器端部署)
5. [启动与测试](#启动与测试)
6. [常见问题排查](#常见问题排查)
7. [性能优化建议](#性能优化建议)

---

## 🏗️ 系统架构概览

### 整体架构

```
┌─────────────────────────────────────────────────┐
│           G1 机器人 (运行主控制程序)             │
│                                                 │
│  1. ASR监听 → 捕获用户语音                      │
│  2. 摄像头拍照 → 获取环境图像                    │
│  3. 打包发送 → 通过ROS2发送给Thor               │
│  4. 接收响应 → 从Thor获取推理结果               │
│  5. 执行动作 → 说话、手势、移动                  │
│                                                 │
└─────────────────────────────────────────────────┘
                    ↕️  ROS2 DDS 通信
┌─────────────────────────────────────────────────┐
│        Jetson Thor 服务器 (VLM推理)              │
│                                                 │
│  1. 接收请求 → 文本 + 图像                       │
│  2. VLM推理 → 视觉语言模型处理                   │
│  3. 决策生成 → 确定回复和动作                    │
│  4. 发送响应 → 返回给G1执行                      │
│                                                 │
└─────────────────────────────────────────────────┘
```

### 数据流向

```
用户说话 → ASR识别 → G1拍照 → 打包JSON
    ↓
发送到 rt/thor_request 话题
    ↓
Thor接收 → VLM推理 → 生成响应
    ↓
发送到 rt/thor_response 话题
    ↓
G1接收 → 分发器路由 → TTS说话 + 执行动作
```

### ROS2 话题通信

| 话题名称 | 发布者 | 订阅者 | 数据内容 | 说明 |
|---------|--------|--------|----------|------|
| `rt/audio_msg` | G1 ASR | G1控制器 | 语音识别文本 | G1内部通信 |
| `rt/thor_request` | G1控制器 | Thor服务器 | 文本+图像(Base64) | 推理请求 |
| `rt/thor_response` | Thor服务器 | G1控制器 | 推理结果JSON | 推理响应 |

---

## 🔧 部署前准备

### 硬件要求

- ✅ **G1机器人**: Unitree G1人形机器人
- ✅ **Jetson Thor**: NVIDIA Jetson设备（或其他GPU服务器）
- ✅ **网线**: 一根以太网线（千兆网线推荐）
- ✅ **网络**: 两台设备通过网线直连，或连接到同一路由器/交换机

### 网络连接方案

#### 方案一：网线直连（推荐 - 最简单）

**适用场景**: 现场没有路由器/交换机，或需要最低延迟

```
G1机器人 ⟺ [网线] ⟺ Jetson Thor
```

**配置步骤**:

1. **用网线连接两台设备**
   ```
   G1的以太网口 ----[网线]---- Thor的以太网口
   ```

2. **在G1上配置静态IP**
   ```bash
   # SSH登录G1
   ssh unitree@<G1当前IP>
   
   # 编辑网络配置
   sudo nano /etc/netplan/01-netcfg.yaml
   ```
   
   添加以下内容（假设网口是eth0）:
   ```yaml
   network:
     version: 2
     renderer: networkd
     ethernets:
       eth0:
         addresses:
           - 192.168.10.10/24
         dhcp4: no
   ```
   
   应用配置:
   ```bash
   sudo netplan apply
   
   # 验证IP
   ip addr show eth0
   # 应该看到: inet 192.168.10.10/24
   ```

3. **在Thor上配置静态IP**
   ```bash
   # SSH登录Thor
   ssh nvidia@<Thor当前IP>
   
   # 编辑网络配置
   sudo nano /etc/netplan/01-netcfg.yaml
   ```
   
   添加以下内容:
   ```yaml
   network:
     version: 2
     renderer: networkd
     ethernets:
       eth0:
         addresses:
           - 192.168.10.20/24
         dhcp4: no
   ```
   
   应用配置:
   ```bash
   sudo netplan apply
   
   # 验证IP
   ip addr show eth0
   # 应该看到: inet 192.168.10.20/24
   ```

4. **测试连通性**
   ```bash
   # 在G1上
   ping 192.168.10.20
   
   # 在Thor上
   ping 192.168.10.10
   
   # 都应该能ping通！
   ```

5. **启动程序时使用配置的IP**
   ```bash
   # G1上 (网口是eth0)
   python -m g1_robot_controller eth0
   
   # Thor上 (网口是eth0)
   python thor_vlm_server.py eth0
   ```

**优点**: 
- ✅ 配置简单，不需要额外设备
- ✅ 延迟最低（直连）
- ✅ 不受路由器/WiFi干扰

**缺点**:
- ⚠️ 两台设备都无法同时访问外网（除非有第二个网口）

---

#### 方案二：通过路由器/交换机连接

**适用场景**: 需要同时访问外网，或现场有网络设备

```
G1机器人 ⟺ [网线] ⟺ 路由器/交换机 ⟺ [网线] ⟺ Jetson Thor
                           ↕
                        外网访问
```

**配置步骤**:

1. **连接网线**
   ```
   G1 ----[网线]---- 路由器 ----[网线]---- Thor
   ```

2. **查看路由器分配的IP**
   
   在G1上:
   ```bash
   ifconfig eth0
   # 或
   ip addr show eth0
   # 记录IP地址，例如: 192.168.1.100
   ```
   
   在Thor上:
   ```bash
   ifconfig eth0
   # 记录IP地址，例如: 192.168.1.101
   ```

3. **测试连通性**
   ```bash
   # 在G1上
   ping <Thor的IP>  # 例如: ping 192.168.1.101
   
   # 在Thor上
   ping <G1的IP>    # 例如: ping 192.168.1.100
   ```

4. **（可选）设置静态IP避免地址变化**
   
   在路由器管理界面，绑定G1和Thor的MAC地址到固定IP:
   ```
   G1的MAC地址  → 192.168.1.100
   Thor的MAC地址 → 192.168.1.101
   ```

5. **启动程序**
   ```bash
   # G1上
   python -m g1_robot_controller eth0
   
   # Thor上
   python thor_vlm_server.py eth0
   ```

**优点**:
- ✅ 两台设备都能访问外网
- ✅ 可以连接更多设备
- ✅ 方便远程调试

**缺点**:
- ⚠️ 延迟稍高（多一跳路由）
- ⚠️ 依赖路由器稳定性

---

#### 方案三：WiFi连接（不推荐）

**仅用于临时测试，不推荐生产环境使用**

```bash
# G1和Thor都连接同一WiFi
# 使用wlan0接口启动程序
python -m g1_robot_controller wlan0
python thor_vlm_server.py wlan0
```

**缺点**:
- ❌ 延迟高、不稳定
- ❌ 带宽受限
- ❌ 干扰多

---

### 网络配置快速参考表

| 方案 | G1 IP | Thor IP | 网口 | 需要路由器 | 能访问外网 | 延迟 |
|------|-------|---------|------|-----------|-----------|------|
| 直连 | 192.168.10.10 | 192.168.10.20 | eth0 | ❌ | ❌ | 最低 |
| 路由器 | DHCP自动 | DHCP自动 | eth0 | ✅ | ✅ | 中等 |
| WiFi | DHCP自动 | DHCP自动 | wlan0 | ✅ | ✅ | 最高 |

**明天部署推荐**: 使用**方案一（网线直连）**，最简单可靠！

---

### 软件要求

#### G1机器人端
```bash
Python >= 3.8
unitree-sdk2py >= 1.0.0
opencv-python >= 4.8.0
```

#### Thor服务器端
```bash
Python >= 3.8
unitree-sdk2py >= 1.0.0
opencv-python >= 4.8.0
numpy >= 1.24.0
torch (根据你的VLM模型需求)
transformers (如果使用HuggingFace模型)
```

### 网络检查

**在配置完网络后，必须确认两台设备能互相通信！**

#### 如果使用方案一（直连）:
```bash
# 在G1上测试
ping 192.168.10.20   # Thor的IP
# 按Ctrl+C停止

# 在Thor上测试
ping 192.168.10.10   # G1的IP
# 按Ctrl+C停止
```

#### 如果使用方案二（路由器）:
```bash
# 先确认各自IP
# G1上:
ip addr show eth0 | grep "inet "
# 记录显示的IP，例如: 192.168.1.100

# Thor上:
ip addr show eth0 | grep "inet "
# 记录显示的IP，例如: 192.168.1.101

# 然后互相ping
# 在G1上:
ping <Thor的IP>

# 在Thor上:
ping <G1的IP>
```

**✅ 只有两边都能ping通，才能继续部署！**

---

### 明天部署的完整步骤总结

**第一步：物理连接**
```
1. 准备一根网线
2. 一端插入G1的以太网口
3. 另一端插入Thor的以太网口
```

**第二步：配置网络（方案一直连）**
```bash
# 在G1上设置IP为 192.168.10.10
sudo nano /etc/netplan/01-netcfg.yaml
# （参考上面方案一的配置）
sudo netplan apply

# 在Thor上设置IP为 192.168.10.20
sudo nano /etc/netplan/01-netcfg.yaml
# （参考上面方案一的配置）
sudo netplan apply
```

**第三步：测试连通性**
```bash
# G1 ping Thor
ping 192.168.10.20

# Thor ping G1
ping 192.168.10.10
```

**第四步：部署代码**
```bash
# 上传代码到两台设备
# （参考下面的"G1机器人端部署"和"Thor服务器端部署"）
```

**第五步：启动系统**
```bash
# 先启动Thor
python thor_vlm_server.py eth0

# 再启动G1
python -m g1_robot_controller eth0
```

**第六步：测试**
```bash
# 对G1说"你好机器人"，观察日志输出
```

---

## 🤖 G1机器人端部署

### 📁 文件部署位置

**将整个项目上传到G1机器人：**

```
/home/unitree/project1/
├── g1_robot_controller/          ← 主控制程序（运行在G1上）
│   ├── main.py                   ← 启动入口
│   ├── dispatcher.py             ← 响应分发器
│   ├── actions/                  ← 动作执行模块
│   ├── comm/                     ← Thor通信模块
│   ├── sensors/                  ← 传感器模块（ASR、摄像头）
│   ├── speech/                   ← 语音合成（TTS）
│   └── utils/                    ← 工具模块
│       └── config.py             ← 配置文件（已包含所有默认配置）
├── g1_agent/                     ← 可选的独立测试脚本
│   ├── g1_asr.py                 ← ASR测试脚本
│   ├── g1_tts.py                 ← TTS测试脚本
│   ├── g1_voice.py               ← 简单对话测试
│   └── g1_voice_gpt.py           ← GPT对话（含10轮上下文）
├── requirements.txt              ← Python依赖
└── 部署指南.md                   ← 本文档
```

### 🚀 部署步骤

#### 1. 上传代码到G1

```bash
# 在你的开发机上执行
scp -r g1_robot_controller/ unitree@<G1_IP>:/home/unitree/project1/
scp requirements.txt unitree@<G1_IP>:/home/unitree/project1/
```

#### 2. SSH登录G1

```bash
ssh unitree@<G1_IP>
# 输入密码
```

#### 3. 安装Python依赖

```bash
cd /home/unitree/project1
pip install -r requirements.txt

# 如果网络慢，使用国内源
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

#### 4. 检查网络接口

```bash
# 查看网络接口
ifconfig

# 常见的网络接口名:
# - eth0  (有线网络)
# - wlan0 (无线网络)
# - enp1s0 (某些系统的有线网络)

# 记住你要使用的接口名，后面启动时需要
```

#### 5. 检查摄像头设备

```bash
# 列出所有视频设备
ls /dev/video*

# 输出示例:
# /dev/video0  /dev/video1  /dev/video4

# G1默认使用 /dev/video4
# 如果你的设备不同，需要修改配置
```

#### 6. 配置参数（可选）

编辑配置文件（如需修改默认值）:

```bash
cd /home/unitree/project1/g1_robot_controller/utils
#### 6. 配置参数（可选）

**默认配置已经可用**，以下是关键配置项（在 `g1_robot_controller/utils/config.py` 中）：

```python
# ROS2 话题配置（已配置好，无需修改）
ASR_TOPIC = "rt/audio_msg"           # ASR语音识别话题
THOR_SEND_TOPIC = "rt/thor_request"  # 发送给Thor的话题
THOR_RECV_TOPIC = "rt/thor_response" # Thor返回的话题

# 摄像头配置（默认值适用于大多数G1机器人）
CAMERA_DEVICE = 4        # 摄像头设备号 (/dev/video4)
CAMERA_WIDTH = 640       # 图像宽度
CAMERA_HEIGHT = 480      # 图像高度
CAMERA_FPS = 30          # 帧率

# TTS配置
DEFAULT_SPEAKER = 1      # 0=中文, 1=英文
TTS_TIMEOUT = 10.0       # TTS超时时间（秒）
```

**如需修改配置，使用环境变量（推荐）**：
```bash
# 修改摄像头设备号
export G1_CAMERA_DEVICE=0

# 修改语言
export G1_SPEAKER=0  # 中文

# 修改网络接口（也可以通过启动参数指定）
export G1_NET_IF=wlan0
```
# 基本启动（假设网络接口是eth0）
python -m g1_robot_controller eth0

# 带调试日志启动（推荐首次部署使用）
python -m g1_robot_controller eth0 --debug
```

**成功启动的日志示例**:
```
============================================================
🤖 G1 机器人控制器 - 正在初始化
============================================================
📡 初始化ROS2 DDS，网络接口: eth0
🔊 初始化文本转语音(TTS)...
📤 初始化Thor数据发送器...
⚙️ 初始化响应分发器...
🎤 初始化语音识别(ASR)监听器...
📥 初始化Thor响应监听器...
============================================================
✅ 所有组件初始化成功！
============================================================
============================================================
🚀 G1 机器人控制器 - 运行中
按 Ctrl+C 停止系统
============================================================
```

#### 8. 保持程序运行（可选 - 使用systemd服务）

创建systemd服务文件:

```bash
sudo nano /etc/systemd/system/g1-controller.service
```

内容:
```ini
[Unit]
Description=G1 Robot Controller
After=network.target

[Service]
Type=simple
User=unitree
WorkingDirectory=/home/unitree/project1
ExecStart=/usr/bin/python3 -m g1_robot_controller eth0
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

启用并启动服务:
```bash
sudo systemctl daemon-reload
sudo systemctl enable g1-controller
sudo systemctl start g1-controller

# 查看状态
sudo systemctl status g1-controller

# 查看日志
journalctl -u g1-controller -f
```

---

## 🖥️ Thor服务器端部署

### 📁 文件部署位置

**只需部署 `thor_vlm_server.py` 到Thor服务器：**

```
/home/nvidia/thor_vlm_server/
├── thor_vlm_server.py       ← Thor端VLM推理服务（已有文件）
├── requirements.txt         ← Thor端依赖
└── models/                  ← VLM模型目录
    └── Qwen2.5-VL-3B-Instruct/
```

**注意**：`thor_vlm_server.py` 已经存在并包含完整实现，无需重新创建。

### 🚀 部署步骤

#### 1. 上传代码到Thor

```bash
# 在你的开发机上执行
scp thor_vlm_server.py nvidia@<Thor_IP>:/home/nvidia/thor_vlm_server/
```

#### 2. SSH登录Thor

```bash
ssh nvidia@<Thor_IP>
# 输入密码
```

#### 3. 创建并安装依赖

```bash
cd /home/nvidia/thor_vlm_server

# 创建 requirements.txt
cat > requirements.txt << 'EOF'
# Thor VLM Server Dependencies
unitree-sdk2py>=1.0.0
opencv-python>=4.8.0
numpy>=1.24.0
torch>=2.0.0
transformers>=4.30.0
pillow>=9.5.0
qwen-vl-utils
EOF

# 安装依赖
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

#### 4. 确认模型路径

编辑 `thor_vlm_server.py`，确认模型路径正确：

```python
# 在 thor_vlm_server.py 的开头配置部分
MODEL_PATH = "/home/bryce/models/Qwen2.5-VL-3B-Instruct"  # 根据实际路径修改
```

#### 5. 启动Thor服务器

```bash
cd /home/nvidia/thor_vlm_server

# 基本启动（假设网络接口是eth0）
python thor_vlm_server.py eth0

# 调试模式（推荐首次部署使用）
python thor_vlm_server.py eth0 --debug
```

**成功启动的日志示例**:
```
============================================================
🖥️  Thor VLM服务器 - 正在初始化
============================================================
📚 上下文管理器初始化: 最大保留 10 轮对话
🔧 初始化Qwen2.5-VL模型...
✅ Qwen2.5-VL模型加载完成
📡 初始化ROS2 DDS，网络接口: eth0
📥 订阅话题: rt/thor_request
📤 创建发布者: rt/thor_response
============================================================
✅ Thor VLM服务器初始化成功！
============================================================
🚀 等待G1请求...
```

---

## 🧪 启动与测试

### 快速测试（可选 - 在完整启动前）

在启动完整系统前，可以单独测试各个组件：

#### 测试1: ASR语音识别
```bash
# 在G1上
cd /home/unitree/project1/g1_agent
python3 g1_asr.py eth0

# 对机器人说话，应该能看到识别结果
```

#### 测试2: TTS语音合成
```bash
# 在G1上
cd /home/unitree/project1/g1_agent
python3 g1_tts.py eth0 "Hello, this is a test"

# 应该能听到机器人说话
```

#### 测试3: 简单对话（无Thor）
```bash
# 在G1上
cd /home/unitree/project1/g1_agent
python3 g1_voice.py eth0

# 对机器人说 "hello"，应该会回复
```

---

### 启动顺序

**完整系统启动顺序（重要）**：

1. **先启动Thor服务器** (否则G1发送的请求无人响应)
2. **再启动G1控制程序**

### 完整启动流程

#### 终端1 - Thor服务器
```bash
ssh nvidia@<Thor_IP>
cd /home/nvidia/thor_vlm_server
python thor_vlm_server.py eth0 --debug
```

#### 终端2 - G1控制器
```bash
ssh unitree@<G1_IP>
cd /home/unitree/project1
python -m g1_robot_controller eth0 --debug
```

### 测试方法

#### 方法1: 语音测试（推荐）

1. 对着G1机器人说话: **"你好机器人"**
2. 观察日志输出:

**G1端日志**:
```
[ASR回调] 接收到: {'text': '你好机器人', 'confidence': 0.95, 'angle': 45.0}
📤 发送给Thor: '你好机器人' (附带图像)
[THOR] Sending to Thor (request_id=xxx): ...
[THOR] Response received (request_id=xxx): {'status': 'success', ...}
🔊 Speaking: 你好！很高兴见到你。
⚙️ Executing gesture: wave
```

**Thor端日志**:
```
📨 收到请求 (ID: xxx): '你好机器人'
📷 图像解码成功: (480, 640, 3)
🧠 VLM推理中... 文本: '你好机器人', 图像大小: (480, 640, 3)
✅ 响应已发送 (ID: xxx)
```

#### 方法2: 手动测试ROS2通信

**在Thor上发送测试响应**:
```python
from unitree_sdk2py.core.channel import ChannelPublisher
from unitree_sdk2py.idl.std_msgs.msg.dds_._String_ import String_
import json

pub = ChannelPublisher("rt/thor_response", String_)
pub.Init()

msg = String_()
msg.data = json.dumps({
    "status": "success",
    "text": "测试响应",
    "action": "wave",
    "action_type": "gesture",
    "confidence": 0.95
})
pub.Write(msg)
print("测试消息已发送")
```

观察G1是否收到并执行。

---

## 🔍 常见问题排查

### 问题1: G1控制器启动失败

#### 症状
```
❌ 初始化失败: [Errno 19] No such device
```

#### 原因
摄像头设备号不正确

#### 解决方法
```bash
# 查看可用摄像头
ls /dev/video*

# 修改配置或环境变量
export G1_CAMERA_DEVICE=0  # 改为实际设备号
python -m g1_robot_controller eth0
```

---

### 问题2: ROS2初始化失败

#### 症状
```
❌ 初始化失败: ChannelFactory initialization failed
```

#### 原因
- 网络接口名称错误
- ROS2 DDS通信问题

#### 解决方法
```bash
# 1. 确认网络接口名称
ifconfig
# 或
ip addr show

# 2. 检查接口是否启用
sudo ifconfig eth0 up

# 3. 使用正确的接口名启动
python -m g1_robot_controller <正确的接口名>
```

---

### 问题3: Thor没有收到G1的请求

#### 症状
- G1日志显示发送成功
- Thor日志没有收到请求的记录

#### 排查步骤

**1. 检查网络连通性**
```bash
# 在G1上
ping <Thor_IP>

# 在Thor上
ping <G1_IP>

# 确保两边都能ping通
```

**2. 检查话题名称是否一致**

G1端 (`g1_robot_controller/utils/config.py`):
```python
THOR_SEND_TOPIC = "rt/thor_request"  # G1发送
THOR_RECV_TOPIC = "rt/thor_response" # G1接收
```

Thor端 (`thor_vlm_server.py`):
```python
RECV_TOPIC = "rt/thor_request"  # Thor接收
SEND_TOPIC = "rt/thor_response" # Thor发送
```

确保完全一致！

**3. 检查ROS2 DDS配置**
```bash
# 在Thor上监听话题
export CYCLONEDDS_URI=<cyclonedds_config.xml>  # 如果有配置文件

# 使用rostopic工具（如果可用）
rostopic list
rostopic echo rt/thor_request
```

**4. 防火墙检查**
```bash
# 临时关闭防火墙测试（Ubuntu/Debian）
sudo ufw disable

# 或添加规则
sudo ufw allow from <对方IP>
```

---

### 问题4: G1收不到Thor的响应

#### 症状
- Thor日志显示响应已发送
- G1日志没有收到响应

#### 解决方法

**1. 检查G1的Thor监听器是否启动**
```
# G1启动日志中应该有:
📥 初始化Thor响应监听器...
📥 Thor listener started on topic: rt/thor_response
```

**2. 检查Thor响应格式**

必须包含 `status` 字段:
```json
{
    "status": "success",  // 必需！
    "text": "...",
    ...
}
```

**3. 调试Thor发送代码**
```python
# 在thor_vlm_server.py的_send_response中添加日志
logger.info(f"🔍 发送的响应内容: {json.dumps(response, ensure_ascii=False)}")
```

---

### 问题5: 摄像头采集失败

#### 症状
```
⚠️ 无法打开摄像头设备: /dev/video4
⚠️ 使用空白图像作为后备方案
```

#### 解决方法

**1. 检查可用摄像头设备**
```bash
ls /dev/video*
# 输出示例: /dev/video0  /dev/video1  /dev/video4
```

**2. 使用环境变量修改设备号**
```bash
# 如果你的摄像头是 /dev/video0
export G1_CAMERA_DEVICE=0
python -m g1_robot_controller eth0
```

**3. 检查摄像头权限**
```bash
ls -l /dev/video4
# 如果权限不足
sudo chmod 666 /dev/video4
```

**4. 检查摄像头是否被占用**
```bash
# 查看哪个进程在使用摄像头
lsof /dev/video4

# 如果有进程占用，停止它
sudo kill <PID>
```

---

### 问题6: TTS语音合成失败

#### 症状
```
❌ AudioClient initialization failed
```

#### 解决方法

**1. 检查AudioClient是否可用**
```python
# SSH登录G1后测试
python3 -c "from unitree_sdk2py.g1.audio.g1_audio_client import AudioClient; print('✅ AudioClient可用')"
```

**2. 使用环境变量修改语言设置**
```bash
# 尝试中文
export G1_SPEAKER=0
python -m g1_robot_controller eth0

# 或英文
export G1_SPEAKER=1
python -m g1_robot_controller eth0
```

**3. 独立测试TTS功能**
```bash
# 使用g1_agent中的测试脚本
cd /home/unitree/project1/g1_agent
python3 g1_tts.py eth0 "Hello, this is a test"
```

---

### 问题7: 动作执行无响应

#### 症状
- Thor响应正确返回
- G1收到响应
- 但机器人没有执行动作

#### 原因
当前是**模拟实现**，只打印日志，不实际控制电机（出于安全考虑）

#### 日志示例
```
⚙️ Executing gesture: wave
[模拟] 执行手势动作: wave
```

#### 说明
- 这是**预期行为**，确保AI交互流程正常工作后，再集成真实电机控制
- 所有动作都会在日志中显示，可以验证逻辑正确性
- 要启用真实动作，需要在 `g1_robot_controller/actions/robot_api.py` 中集成Unitree SDK的电机控制API

#### 未来集成真实API的位置
- `g1_robot_controller/actions/robot_api.py` - 电机控制接口
- `g1_robot_controller/actions/gesture.py` - 手势动作实现  
- `g1_robot_controller/actions/movement.py` - 移动控制实现

---

### 问题8: 日志显示JSON解析失败

#### 症状
```
⚠️ Failed to parse Thor JSON: ... - Expecting value: line 1 column 1
```

#### 原因
Thor发送的不是有效的JSON格式

#### 解决方法

**在Thor端检查发送的数据**:
```python
# 在_send_response中添加验证
import json

response_json = json.dumps(response, ensure_ascii=False)
logger.info(f"JSON内容: {response_json}")

# 验证是否能解析
try:
    json.loads(response_json)
    logger.info("✅ JSON格式正确")
except:
    logger.error("❌ JSON格式错误")
```

---

### 问题9: 系统运行一段时间后变慢

#### 症状
- 初期运行正常
- 运行一段时间后响应变慢
- 内存占用升高

#### 可能原因
1. 摄像头资源未释放
2. 线程/连接泄漏
3. 日志文件过大

#### 解决方法

**1. 检查资源释放**
```python
# 确保摄像头正确释放
camera.release()
```

**2. 限制日志大小**
```python
# 在启动脚本中配置日志轮转
import logging
from logging.handlers import RotatingFileHandler

handler = RotatingFileHandler(
    'g1_controller.log',
    maxBytes=10*1024*1024,  # 10MB
    backupCount=3
)
logging.getLogger().addHandler(handler)
```

**3. 监控资源使用**
```bash
# 监控CPU和内存
htop

# 监控进程
ps aux | grep python
```

---

## ⚡ 性能优化建议

### 1. 网络优化

#### 使用有线网络
```bash
# 优先使用有线网络（更稳定、延迟低）
python -m g1_robot_controller eth0  # 而非 wlan0
```

#### 调整图像分辨率
```python
# 在 utils/config.py 中
CAMERA_WIDTH = 320   # 从640降到320（减少传输数据量）
CAMERA_HEIGHT = 240  # 从480降到240
```

### 2. 图像传输优化

#### 压缩图像
编辑 `comm/thor_sender.py`:
```python
# 使用JPEG压缩而非PNG
success, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
```

### 3. VLM推理优化

#### 使用批处理（如果适用）
```python
# Thor端支持批量推理
# 累积多个请求后一起处理
```

#### 使用TensorRT加速
```python
# 将PyTorch模型转换为TensorRT
# 可显著提升推理速度
```

### 4. 日志级别调整

生产环境关闭DEBUG日志:
```bash
# 不使用 --debug 参数
python -m g1_robot_controller eth0

# 或在代码中设置
logging.getLogger().setLevel(logging.WARNING)
```

---

## 📊 监控与调试

### g1_agent中的测试工具

项目包含多个独立测试脚本，用于调试各个组件：

#### 1. ASR测试 (`g1_agent/g1_asr.py`)
```bash
python3 g1_asr.py eth0
# 功能: 监听并显示ASR识别结果
# 用途: 验证语音识别是否正常工作
```

#### 2. TTS测试 (`g1_agent/g1_tts.py`)
```bash
python3 g1_tts.py eth0 "要说的内容"
# 功能: 测试文本转语音，自动识别中英文
# 用途: 验证语音合成是否正常
```

#### 3. 简单对话测试 (`g1_agent/g1_voice.py`)
```bash
python3 g1_voice.py eth0
# 功能: ASR + 简单规则对话 + TTS
# 用途: 验证基本对话流程（不需要Thor）
```

#### 4. GPT对话测试 (`g1_agent/g1_voice_gpt.py`)
```bash
python3 g1_voice_gpt.py eth0
# 功能: ASR + GPT-4 + 10轮上下文 + TTS
# 用途: 验证GPT集成和上下文管理（不需要Thor）
# 注意: 需要配置OpenAI API Key
```

---

### 实时监控系统状态

#### G1端监控
```bash
# 终端1: 运行程序
python -m g1_robot_controller eth0 --debug

# 终端2: 监控系统资源
watch -n 1 "ps aux | grep g1_robot_controller"

# 终端3: 实时查看日志
tail -f /var/log/g1_controller.log  # 如果配置了日志文件
```

#### Thor端监控
```bash
# 终端1: 运行服务器
python thor_vlm_server.py eth0 --debug

# 终端2: 监控GPU使用
watch -n 1 nvidia-smi

# 终端3: 监控网络流量
iftop -i eth0
```

### 性能指标

记录关键性能指标:
- ASR识别延迟: ~100ms
- 图像采集时间: ~50ms
- 网络传输时间: ~50-200ms
- VLM推理时间: 取决于模型（1-5秒）
- TTS合成时间: ~500-2000ms
- 动作执行时间: ~100-500ms

**总体端到端延迟**: 约2-8秒

---

## 📝 部署检查清单

### 部署前

- [ ] G1和Thor通过网线连接
- [ ] 两台设备配置了静态IP（如使用直连方案）
- [ ] 两台设备能互相ping通
- [ ] Python版本 >= 3.8
- [ ] unitree-sdk2py已安装

### G1端

- [ ] 整个项目已上传到G1 (`/home/unitree/project1/`)
- [ ] requirements.txt依赖已安装
- [ ] 网络接口名称已确认 (`ifconfig`)
- [ ] 摄像头设备可用 (`ls /dev/video*`)
- [ ] 配置文件 `g1_robot_controller/utils/config.py` 已检查
- [ ] 可选: 单独测试组件（ASR/TTS/对话）正常

### Thor端

- [ ] `thor_vlm_server.py` 已部署
- [ ] requirements.txt依赖已安装
- [ ] 模型路径已配置正确
- [ ] Qwen2.5-VL模型已下载到指定路径
- [ ] 网络接口名称已确认
- [ ] 能成功启动服务器

### 功能测试

- [ ] Thor服务器启动成功，等待请求
- [ ] G1控制器启动成功
- [ ] G1能捕获ASR语音
- [ ] G1能拍摄照片
- [ ] G1能发送请求给Thor（查看日志）
- [ ] Thor能接收请求（查看日志）
- [ ] Thor能执行VLM推理
- [ ] Thor能发送响应给G1
- [ ] G1能接收Thor响应
- [ ] G1能执行TTS语音合成
- [ ] 完整交互流程正常（对话 + 动作日志显示）

---

## 🎓 进阶功能

### 1. 使用GPT进行对话（不依赖Thor）

如果想测试纯文本对话（不使用视觉），可以使用 `g1_agent/g1_voice_gpt.py`：

```bash
# 配置OpenAI API Key
export OPENAI_API_KEY="your-api-key-here"

# 启动GPT对话模式
cd /home/unitree/project1/g1_agent
python3 g1_voice_gpt.py eth0
```

**功能特点**：
- ✅ 10轮上下文管理
- ✅ 文本过滤（防乱码）
- ✅ 置信度过滤
- ✅ 节流控制（防重复触发）
- ✅ GPT-4集成

### 2. 切换中英文

```bash
# 使用中文
export G1_SPEAKER=0
python -m g1_robot_controller eth0

# 使用英文
export G1_SPEAKER=1
python -m g1_robot_controller eth0
```

### 3. 调试模式

```bash
# 启用详细日志
python -m g1_robot_controller eth0 --debug
python thor_vlm_server.py eth0 --debug
```

---

## 🆘 紧急联系与备份

### 快速恢复步骤

如果系统出现严重问题:

1. **停止所有程序**: Ctrl+C
2. **重启ROS2通信**:
   ```bash
   # 清理DDS缓存
   rm -rf ~/.ros/
   ```
3. **重启设备**:
   ```bash
   sudo reboot
   ```
4. **恢复默认配置**: 使用备份的config.py

### 日志收集

如需报告问题，收集以下信息:

```bash
# G1端
python -m g1_robot_controller eth0 --debug > g1_log.txt 2>&1

# Thor端
python thor_vlm_server.py eth0 --debug > thor_log.txt 2>&1

# 系统信息
uname -a > system_info.txt
ifconfig >> system_info.txt
pip list >> system_info.txt
```

---

## 🎉 成功部署标志

当你看到以下现象时，说明部署成功:

1. ✅ Thor和G1都启动无报错
2. ✅ 对G1说话，能看到ASR捕获日志
3. ✅ G1自动拍照并发送给Thor
4. ✅ Thor收到请求并执行VLM推理
5. ✅ Thor发送响应给G1
6. ✅ G1语音回复
7. ✅ G1显示动作执行日志（模拟执行）
8. ✅ 整个流程延迟合理（<10秒）

**恭喜！你的G1机器人VLM交互系统已经部署成功！** 🎊

---

## 📚 项目文件说明

### g1_robot_controller/ (主控制系统)
- 完整的G1机器人控制框架
- 包含ASR监听、摄像头采集、Thor通信、TTS语音、动作执行
- 使用环境变量或配置文件管理参数

### g1_agent/ (独立测试脚本)
这些是**独立测试工具**，不是主系统的一部分：

- `g1_asr.py` - ASR测试脚本
- `g1_tts.py` - TTS测试脚本  
- `g1_voice.py` - 简单对话测试（规则匹配）
- `g1_voice_gpt.py` - GPT对话测试（10轮上下文）
- `g1_front_cam.py` - RealSense摄像头测试
- `finall_g1_agent/` - 早期原型代码

**用途**: 在部署主系统前，独立测试各个组件功能

### thor_vlm_server.py (Thor端)
- Qwen2.5-VL-3B-Instruct集成
- 10轮上下文管理
- Base64图像处理
- 情感识别和动作决策

---

**文档版本**: 2.0  
**最后更新**: 2025年11月26日  
**项目**: G1机器人VLM交互系统

如有问题，请参考"常见问题排查"章节或使用`g1_agent`中的测试脚本进行调试。
